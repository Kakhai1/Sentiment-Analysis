{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip data\n",
    "import zipfile\n",
    "with zipfile.ZipFile('Resources/data.zip') as zip:\n",
    "    zip.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2183</th>\n",
       "      <td>40408</td>\n",
       "      <td>Time to leave California and head back to snow...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>149408</td>\n",
       "      <td>Beginning Today, @united Expands Their Embraer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>21714</td>\n",
       "      <td>There are like 3 companies I would pack up and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>84497</td>\n",
       "      <td>@VirginAmerica Is VX258 going to be cancelled ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635</th>\n",
       "      <td>86857</td>\n",
       "      <td>Guys @VirginAmerica switched the almonds to ro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet  label\n",
       "2183   40408  Time to leave California and head back to snow...      1\n",
       "3189  149408  Beginning Today, @united Expands Their Embraer...      1\n",
       "1919   21714  There are like 3 companies I would pack up and...      1\n",
       "2610   84497  @VirginAmerica Is VX258 going to be cancelled ...      1\n",
       "2635   86857  Guys @VirginAmerica switched the almonds to ro...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Load data and set labels\n",
    "data_complaint = pd.read_csv('data/complaint1700.csv')\n",
    "data_complaint['label'] = 0\n",
    "data_non_complaint = pd.read_csv('data/noncomplaint1700.csv')\n",
    "data_non_complaint['label'] = 1\n",
    "\n",
    "# Concatenate complaining and non-complaining data\n",
    "data = pd.concat([data_complaint, data_non_complaint], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Drop 'airline' column\n",
    "data.drop(['airline'], inplace=True, axis=1)\n",
    "\n",
    "# Display 5 random samples\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.tweet.values\n",
    "y = data.label.values\n",
    "\n",
    "X_train, X_val, y_train, y_val =\\\n",
    "    train_test_split(X, y, test_size=0.1, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3357</th>\n",
       "      <td>127095</td>\n",
       "      <td>@jeffjarvis On @united I have never seen a pil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3625</th>\n",
       "      <td>136966</td>\n",
       "      <td>To add to my @AmericanAir delayed flight, we h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>21697</td>\n",
       "      <td>Had a terrible experience with @united this we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>237</td>\n",
       "      <td>@SouthwestAir your customer service sucks! You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>52525</td>\n",
       "      <td>As always, @united makes my traveling as diffi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet\n",
       "3357  127095  @jeffjarvis On @united I have never seen a pil...\n",
       "3625  136966  To add to my @AmericanAir delayed flight, we h...\n",
       "554    21697  Had a terrible experience with @united this we...\n",
       "6        237  @SouthwestAir your customer service sucks! You...\n",
       "1334   52525  As always, @united makes my traveling as diffi..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data\n",
    "test_data = pd.read_csv('data/test_data.csv')\n",
    "\n",
    "# Keep important columns\n",
    "test_data = test_data[['id', 'tweet']]\n",
    "\n",
    "# Display 5 samples from the test data\n",
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Assistant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# Uncomment to download \"stopwords\"\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def text_preprocessing(s):\n",
    "    \"\"\"\n",
    "    - Lowercase the sentence\n",
    "    - Change \"'t\" to \"not\"\n",
    "    - Remove \"@name\"\n",
    "    - Isolate and remove punctuations except \"?\"\n",
    "    - Remove other special characters\n",
    "    - Remove stop words except \"not\" and \"can\"\n",
    "    - Remove trailing whitespace\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    # Change 't to 'not'\n",
    "    s = re.sub(r\"\\'t\", \" not\", s)\n",
    "    # Remove @name\n",
    "    s = re.sub(r'(@.*?)[\\s]', ' ', s)\n",
    "    # Isolate and remove punctuations except '?'\n",
    "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', s)\n",
    "    s = re.sub(r'[^\\w\\s\\?]', ' ', s)\n",
    "    # Remove some special characters\n",
    "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
    "    # Remove stopwords except 'not' and 'can'\n",
    "    s = \" \".join([word for word in s.split()\n",
    "                  if word not in stopwords.words('english')\n",
    "                  or word in ['not', 'can']])\n",
    "    # Remove trailing whitespace\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 22.5 s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Preprocess text\n",
    "X_train_preprocessed = np.array([text_preprocessing(text) for text in X_train])\n",
    "X_val_preprocessed = np.array([text_preprocessing(text) for text in X_val])\n",
    "\n",
    "# Calculate TF-IDF\n",
    "tf_idf = TfidfVectorizer(ngram_range=(1, 3),\n",
    "                         binary=True,\n",
    "                         smooth_idf=False)\n",
    "X_train_tfidf = tf_idf.fit_transform(X_train_preprocessed)\n",
    "X_val_tfidf = tf_idf.transform(X_val_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "def get_auc_CV(model):\n",
    "    \"\"\"\n",
    "    Return the average AUC score from cross-validation.\n",
    "    \"\"\"\n",
    "    # Set KFold to shuffle data before the split\n",
    "    kf = StratifiedKFold(5, shuffle=True, random_state=1)\n",
    "\n",
    "    # Get AUC scores\n",
    "    auc = cross_val_score(\n",
    "        model, X_train_tfidf, y_train, scoring=\"roc_auc\", cv=kf)\n",
    "\n",
    "    return auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MultinomialNB.__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Assistant\\OneDrive - LEISHMAN FINANCIAL SERVICES PTY LTD\\Desktop\\temp\\Dev\\Sentiment-Analysis\\test.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Assistant/OneDrive%20-%20LEISHMAN%20FINANCIAL%20SERVICES%20PTY%20LTD/Desktop/temp/Dev/Sentiment-Analysis/test.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnaive_bayes\u001b[39;00m \u001b[39mimport\u001b[39;00m MultinomialNB\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Assistant/OneDrive%20-%20LEISHMAN%20FINANCIAL%20SERVICES%20PTY%20LTD/Desktop/temp/Dev/Sentiment-Analysis/test.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m res \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries([get_auc_CV(MultinomialNB(i))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Assistant/OneDrive%20-%20LEISHMAN%20FINANCIAL%20SERVICES%20PTY%20LTD/Desktop/temp/Dev/Sentiment-Analysis/test.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                  \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39marange(\u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m0.1\u001b[39m)],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Assistant/OneDrive%20-%20LEISHMAN%20FINANCIAL%20SERVICES%20PTY%20LTD/Desktop/temp/Dev/Sentiment-Analysis/test.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                 index\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marange(\u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m0.1\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Assistant/OneDrive%20-%20LEISHMAN%20FINANCIAL%20SERVICES%20PTY%20LTD/Desktop/temp/Dev/Sentiment-Analysis/test.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m best_alpha \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(res\u001b[39m.\u001b[39midxmax(), \u001b[39m2\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Assistant/OneDrive%20-%20LEISHMAN%20FINANCIAL%20SERVICES%20PTY%20LTD/Desktop/temp/Dev/Sentiment-Analysis/test.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest alpha: \u001b[39m\u001b[39m'\u001b[39m, best_alpha)\n",
      "\u001b[1;32mc:\\Users\\Assistant\\OneDrive - LEISHMAN FINANCIAL SERVICES PTY LTD\\Desktop\\temp\\Dev\\Sentiment-Analysis\\test.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Assistant/OneDrive%20-%20LEISHMAN%20FINANCIAL%20SERVICES%20PTY%20LTD/Desktop/temp/Dev/Sentiment-Analysis/test.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnaive_bayes\u001b[39;00m \u001b[39mimport\u001b[39;00m MultinomialNB\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Assistant/OneDrive%20-%20LEISHMAN%20FINANCIAL%20SERVICES%20PTY%20LTD/Desktop/temp/Dev/Sentiment-Analysis/test.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m res \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries([get_auc_CV(MultinomialNB(i))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Assistant/OneDrive%20-%20LEISHMAN%20FINANCIAL%20SERVICES%20PTY%20LTD/Desktop/temp/Dev/Sentiment-Analysis/test.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                  \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39marange(\u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m0.1\u001b[39m)],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Assistant/OneDrive%20-%20LEISHMAN%20FINANCIAL%20SERVICES%20PTY%20LTD/Desktop/temp/Dev/Sentiment-Analysis/test.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                 index\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marange(\u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m0.1\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Assistant/OneDrive%20-%20LEISHMAN%20FINANCIAL%20SERVICES%20PTY%20LTD/Desktop/temp/Dev/Sentiment-Analysis/test.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m best_alpha \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(res\u001b[39m.\u001b[39midxmax(), \u001b[39m2\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Assistant/OneDrive%20-%20LEISHMAN%20FINANCIAL%20SERVICES%20PTY%20LTD/Desktop/temp/Dev/Sentiment-Analysis/test.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest alpha: \u001b[39m\u001b[39m'\u001b[39m, best_alpha)\n",
      "\u001b[1;31mTypeError\u001b[0m: MultinomialNB.__init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "res = pd.Series([get_auc_CV(MultinomialNB(i))\n",
    "                 for i in np.arange(1, 10, 0.1)],\n",
    "                index=np.arange(1, 10, 0.1))\n",
    "\n",
    "best_alpha = np.round(res.idxmax(), 2)\n",
    "print('Best alpha: ', best_alpha)\n",
    "\n",
    "plt.plot(res)\n",
    "plt.title('AUC vs. Alpha')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('AUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "\n",
    "def evaluate_roc(probs, y_true):\n",
    "    \"\"\"\n",
    "    - Print AUC and accuracy on the test set\n",
    "    - Plot ROC\n",
    "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
    "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
    "    \"\"\"\n",
    "    preds = probs[:, 1]\n",
    "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f'AUC: {roc_auc:.4f}')\n",
    "       \n",
    "    # Get accuracy over the test set\n",
    "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "    \n",
    "    # Plot ROC AUC\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8451\n",
      "Accuracy: 75.59%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute predicted probabilities\n",
    "nb_model = MultinomialNB(alpha=1.8)\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "probs = nb_model.predict_proba(X_val_tfidf)\n",
    "\n",
    "# Evaluate the classifier\n",
    "evaluate_roc(probs, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    - Remove entity mentions (eg. '@united')\n",
    "    - Correct errors (eg. '&amp;' to '&')\n",
    "    @param    text (str): a string to be processed.\n",
    "    @return   text (Str): the processed string.\n",
    "    \"\"\"\n",
    "    # Remove '@name'\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "\n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  @united I'm having issues. Yesterday I rebooked for 24 hours after I was supposed to fly, now I can't log on &amp; check in. Can you help?\n",
      "Processed:  I'm having issues. Yesterday I rebooked for 24 hours after I was supposed to fly, now I can't log on & check in. Can you help?\n"
     ]
    }
   ],
   "source": [
    "# Print sentence 0\n",
    "print('Original: ', X[0])\n",
    "print('Processed: ', text_preprocessing(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Create a function to tokenize a set of texts\n",
    "def preprocessing_for_bert(data):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=text_preprocessing(sent),  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length\n",
    "            #return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True      # Return attention mask\n",
    "            )\n",
    "        \n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:  68\n"
     ]
    }
   ],
   "source": [
    "# Concatenate train data and test data\n",
    "all_tweets = np.concatenate([data.tweet.values, test_data.tweet.values])\n",
    "\n",
    "# Encode our concatenated data\n",
    "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_tweets]\n",
    "\n",
    "# Find the maximum length\n",
    "max_len = max([len(sent) for sent in encoded_tweets])\n",
    "print('Max length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\Users\\Assistant\\anaconda3\\envs\\dev\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  @united I'm having issues. Yesterday I rebooked for 24 hours after I was supposed to fly, now I can't log on &amp; check in. Can you help?\n",
      "Token IDs:  [101, 1045, 1005, 1049, 2383, 3314, 1012, 7483, 1045, 2128, 8654, 2098, 2005, 2484, 2847, 2044, 1045, 2001, 4011, 2000, 4875, 1010, 2085, 1045, 2064, 1005, 1056, 8833, 2006, 1004, 4638, 1999, 1012, 2064, 2017, 2393, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "# Specify `MAX_LEN`\n",
    "MAX_LEN = 64\n",
    "\n",
    "# Print sentence 0 and its encoded token ids\n",
    "token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n",
    "print('Original: ', X[0])\n",
    "print('Token IDs: ', token_ids)\n",
    "\n",
    "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
    "print('Tokenizing data...')\n",
    "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
    "val_inputs, val_masks = preprocessing_for_bert(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Convert other data types to torch.Tensor\n",
    "train_labels = torch.tensor(y_train)\n",
    "val_labels = torch.tensor(y_val)\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 156 ms\n",
      "Wall time: 1.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "# Create the BertClassfier class\n",
    "class BertClassifier(nn.Module):\n",
    "    \"\"\"Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, freeze_bert=False):\n",
    "        \"\"\"\n",
    "        @param    bert: a BertModel object\n",
    "        @param    classifier: a torch.nn.Module classifier\n",
    "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
    "        \"\"\"\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 768, 50, 2\n",
    "\n",
    "        # Instantiate BERT model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "        # Freeze the BERT model\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "def initialize_model(epochs=4):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "    \"\"\"\n",
    "    # Instantiate Bert Classifier\n",
    "    bert_classifier = BertClassifier(freeze_bert=False)\n",
    "\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    bert_classifier.to(device)\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=5e-5,    # Default learning rate\n",
    "                      eps=1e-8    # Default epsilon value\n",
    "                      )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "    return bert_classifier, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# Specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
    "    \"\"\"Train the BertClassifier model.\n",
    "    \"\"\"\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "        # Print the header of the result table\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20 batches\n",
    "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # Calculate time elapsed for 20 batches\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                # Print training results\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                # Reset batch tracking variables\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if evaluation == True:\n",
    "            # After the completion of each training epoch, measure the model's performance\n",
    "            # on our validation set.\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            \n",
    "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            print(\"-\"*70)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
    "    on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\Assistant\\anaconda3\\envs\\dev\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)    # Set  seed for reproducibility\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
    "train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def bert_predict(model, test_dataloader):\n",
    "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
    "    on the test set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    all_logits = []\n",
    "\n",
    "    # For each batch in our test set...\n",
    "    for batch in test_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "        all_logits.append(logits)\n",
    "    \n",
    "    # Concatenate logits from each batch\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "\n",
    "    # Apply softmax to calculate probabilities\n",
    "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predicted probabilities on the test set\n",
    "probs = bert_predict(bert_classifier, val_dataloader)\n",
    "\n",
    "# Evaluate the Bert classifier\n",
    "evaluate_roc(probs, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the train set and the validation set\n",
    "full_train_data = torch.utils.data.ConcatDataset([train_data, val_data])\n",
    "full_train_sampler = RandomSampler(full_train_data)\n",
    "full_train_dataloader = DataLoader(full_train_data, sampler=full_train_sampler, batch_size=32)\n",
    "\n",
    "# Train the Bert Classifier on the entire training data\n",
    "set_seed(42)\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
    "train(bert_classifier, full_train_dataloader, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run `preprocessing_for_bert` on the test set\n",
    "print('Tokenizing data...')\n",
    "test_inputs, test_masks = preprocessing_for_bert(test_data.tweet)\n",
    "\n",
    "# Create the DataLoader for our test set\n",
    "test_dataset = TensorDataset(test_inputs, test_masks)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predicted probabilities on the test set\n",
    "probs = bert_predict(bert_classifier, test_dataloader)\n",
    "\n",
    "# Get predictions from the probabilities\n",
    "threshold = 0.9\n",
    "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
    "\n",
    "# Number of tweets predicted non-negative\n",
    "print(\"Number of tweets predicted non-negative: \", preds.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = test_data[preds==1]\n",
    "list(output.sample(20).tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
